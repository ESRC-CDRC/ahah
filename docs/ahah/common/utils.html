<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ahah.common.utils API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ahah.common.utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
from pathlib import Path
from typing import Union

import cudf
import dask_geopandas
import geopandas as gpd
import numpy as np
import pandas as pd
from shapely.geometry import Polygon
from tqdm import tqdm

from ahah.common.logger import logger

DataFrame = Union[pd.DataFrame, cudf.DataFrame]


class Config:
    &#34;&#34;&#34;Misc constants required throughout&#34;&#34;&#34;

    DATA_PATH = Path(os.environ[&#34;PROJECT_ROOT&#34;]) / &#34;data&#34;
    RAW_DATA = DATA_PATH / &#34;raw&#34;
    PROCESSED_DATA = DATA_PATH / &#34;processed&#34;
    OUT_DATA = DATA_PATH / &#34;out&#34;
    OS_GRAPH = PROCESSED_DATA / &#34;osm&#34;
    HW_DATA = RAW_DATA / &#34;os_highways&#34; / &#34;oproad_gb.gpkg&#34;

    POI_LIST = [
        &#34;gpp&#34;,
        &#34;dentists&#34;,
        &#34;pharmacies&#34;,
        &#34;hospitals&#34;,
        &#34;greenspace&#34;,
        &#34;bluespace&#34;,
    ]

    NODE_COLS = [&#34;node_id&#34;, &#34;easting&#34;, &#34;northing&#34;]
    EDGE_COLS = [&#34;source&#34;, &#34;target&#34;, &#34;time_weighted&#34;, &#34;length&#34;]

    # WARN:In final version find out exact dates and update Scotland to newest.
    # https://digital.nhs.uk/services/organisation-data-service/data-downloads
    NHS_URL = &#34;https://files.digital.nhs.uk/assets/ods/current/&#34;
    NHS_FILES = {
        # 25 Feburary 2022 - Checked 22 March 2022
        &#34;gpp&#34;: &#34;epraccur.zip&#34;,
        # &#34;&#34;
        &#34;dentists&#34;: &#34;egdpprac.zip&#34;,
        # &#34;&#34;
        &#34;pharmacies&#34;: &#34;edispensary.zip&#34;,
        # &#34;&#34;
        &#34;hospitals&#34;: &#34;ets.zip&#34;,
    }
    NHS_SCOT_URL = &#34;https://www.opendata.nhs.scot/dataset/&#34;
    NHS_SCOT_FILES = {
        # GP Practices and List sizes Jan 2022
        &#34;gpp&#34;: &#34;f23655c3-6e23-4103-a511-a80d998adb90/resource&#34;
        &#34;/a794d603-95ab-4309-8c92-b48970478c14/download&#34;
        &#34;/practice_contactdetails_jan2022.csv&#34;,
        # Dental Practices June 2021
        &#34;dentists&#34;: &#34;2f218ba7-6695-4b22-867d-41383ae36de7/resource&#34;
        &#34;/12bf4b02-15e6-41d0-9ae0-18663b463833/download&#34;
        &#34;/nhs-dental-practices-and-nhs-dental-registrations-as-at-30th-june-2021.csv&#34;,
        # Current NHS Hospitals in Scotland 16th December 2021
        &#34;hospitals&#34;: &#34;cbd1802e-0e04-4282-88eb-d7bdcfb120f0/resource&#34;
        &#34;/c698f450-eeed-41a0-88f7-c1e40a568acc/download&#34;
        &#34;/current-hospital_flagged20211216.csv&#34;,
        # Dispenser Details October 2021
        &#34;pharmacies&#34;: &#34;a30fde16-1226-49b3-b13d-eb90e39c2058/resource&#34;
        &#34;/9f9db0c9-8b5a-4813-b586-7e0084bbf9b0/download&#34;
        &#34;/dispenser_contactdetails_oct2021.csv&#34;,
    }
    NHS_WALES_URL = (
        &#34;https://nwssp.nhs.wales/ourservices/&#34;
        &#34;primary-care-services/primary-care-services-documents/&#34;
    )
    NHS_WALES_FILES = {
        &#34;pharmacy&#34;: (
            &#34;pharmacy-practice-dispensing-data-docs&#34;
            &#34;/dispensing-data-report-november-2021&#34;
        )
    }


def combine_lsoa(eng, scot, wales):
    eng = gpd.read_file(eng)[[&#34;code&#34;, &#34;name&#34;, &#34;geometry&#34;]].rename(
        columns={&#34;code&#34;: &#34;lsoa11&#34;}
    )
    scot = gpd.read_file(scot)[[&#34;DataZone&#34;, &#34;Name&#34;, &#34;geometry&#34;]].rename(
        columns={&#34;DataZone&#34;: &#34;lsoa11&#34;, &#34;Name&#34;: &#34;name&#34;}
    )
    wales = gpd.read_file(wales)[[&#34;LSOA11Code&#34;, &#34;lsoa11name&#34;, &#34;geometry&#34;]].rename(
        columns={&#34;LSOA11Code&#34;: &#34;lsoa11&#34;, &#34;lsoa11name&#34;: &#34;name&#34;}
    )
    return eng.append(scot).append(wales)


def fix_postcodes(df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Ensure all postcodes follow correct spacing format

    Parameters
    ----------
    series : DataFrame
        Df with Series of postcodes as strings

    Returns
    -------
    DataFrame:
        Df with correctly formatted series of postcodes
    &#34;&#34;&#34;
    df[&#34;postcode&#34;] = df[&#34;postcode&#34;].str.replace(&#34; &#34;, &#34;&#34;)
    df[&#34;postcode&#34;] = df[&#34;postcode&#34;].str[:-3] + &#34; &#34; + df[&#34;postcode&#34;].str[-3:]
    return df


def find_partial_pc(df, postcodes):
    &#34;&#34;&#34;
    Find postcodes that have partially correct first characters.

    Splits postcodes into two and uses first half to match to likely nearest
    correct postcode location if the postcode cannot be found in whole postcode
    dataset.

    Parameters
    ----------
    poi : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe containing series of postcodes
    poi_pc : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe with df postcodes
    postcodes : Union[pd.DataFrame, cudf.DataFrame]
        Dataframe of all postcodes
    Returns
    -------
    Union[pd.DataFrame, cudf.DataFrame]:
        POI dataframe with inferred postcodes
    &#34;&#34;&#34;
    remove_pcs = &#34;|&#34;.join([&#34;GY&#34;, &#34;JE&#34;, &#34;IM&#34;, &#34;BF&#34;])

    df = df[~df.index.str.contains(remove_pcs).values]
    missing = df[df[&#34;easting&#34;].isna()].reset_index()
    postcodes = postcodes.reset_index()

    missing[&#34;partial&#34;] = missing[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]
    postcodes[&#34;partial&#34;] = postcodes[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]

    missing = missing.set_index(&#34;partial&#34;).drop(
        [&#34;postcode&#34;, &#34;easting&#34;, &#34;northing&#34;], axis=1
    )
    postcodes = postcodes.set_index(&#34;partial&#34;)

    missing = (
        missing.join(postcodes)
        .reset_index()
        .drop_duplicates(&#34;partial&#34;)
        .drop(&#34;partial&#34;, axis=1)
        .set_index(&#34;postcode&#34;)
        .dropna()
    )

    return df.dropna().append(missing)


def clean_postcodes(path: Path, current: bool) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning postcodes...&#34;)

    dtypes = {
        &#34;pcd&#34;: &#34;str&#34;,
        &#34;lsoa11&#34;: &#34;str&#34;,
        &#34;oseast1m&#34;: &#34;int&#34;,
        &#34;osnrth1m&#34;: &#34;int&#34;,
        &#34;doterm&#34;: &#34;int&#34;,
        &#34;ctry&#34;: &#34;str&#34;,
    }
    column_names = {
        &#34;pcd&#34;: &#34;postcode&#34;,
        &#34;oseast1m&#34;: &#34;easting&#34;,
        &#34;osnrth1m&#34;: &#34;northing&#34;,
    }

    postcodes = (
        cudf.read_csv(
            path,
            usecols=[*dtypes],
            dtype=dtypes,
        )
        .rename(columns=column_names)
        .set_index(&#34;ctry&#34;)
        .loc[[&#34;E92000001&#34;, &#34;S92000003&#34;, &#34;W92000004&#34;]]
        .pipe(fix_postcodes)
        .dropna(subset=[&#34;northing&#34;, &#34;easting&#34;])
        .set_index(&#34;postcode&#34;)
        .drop_duplicates()
    )

    if not current:
        return postcodes.drop(&#34;doterm&#34;, axis=1)

    # 2 scottish LSOA have no current postcodes - so use nearby ones
    pc_current = postcodes[postcodes[&#34;doterm&#34;].isnull()]
    missing = postcodes.copy()
    missing.loc[&#34;G21 4QJ&#34;, &#34;lsoa11&#34;] = &#34;S01010206&#34;
    missing.loc[[&#34;G21 1NL&#34;, &#34;G21 1RR&#34;], &#34;lsoa11&#34;] = &#34;S01010226&#34;

    return (
        pc_current.append(postcodes[postcodes[&#34;lsoa11&#34;] == &#34;S01011827&#34;])
        .append(missing.loc[[&#34;G21 4QJ&#34;, &#34;G21 1NL&#34;, &#34;G21 1RR&#34;]])
        .drop(&#34;doterm&#34;, axis=1)
    )


def clean_dentists(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning dentists...&#34;)

    edent = (
        cudf.read_csv(england, usecols=[0, 9], header=None)
        .rename(columns={&#34;0&#34;: &#34;dentist&#34;, &#34;9&#34;: &#34;postcode&#34;})
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    sdent = (
        cudf.read_csv(scotland)
        .rename(
            columns={
                &#34;﻿DentalPracticeCode&#34;: &#34;dentist&#34;,
                &#34;Postcode&#34;: &#34;postcode&#34;,
            }
        )[[&#34;dentist&#34;, &#34;postcode&#34;]]
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    return edent.append(sdent).reset_index()


def clean_gpp(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning gpp...&#34;)

    egpp = (
        cudf.read_csv(england, usecols=[0, 9, 11], header=None)
        .rename(columns={&#34;0&#34;: &#34;gpp&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;})
        .pipe(lambda x: x[x[&#34;close&#34;].isna()])
        .drop(&#34;close&#34;, axis=1)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    sgpp = (
        cudf.read_csv(scotland, usecols=[&#34;PracticeCode&#34;, &#34;Postcode&#34;])
        .rename(columns={&#34;PracticeCode&#34;: &#34;gpp&#34;, &#34;Postcode&#34;: &#34;postcode&#34;})
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    return egpp.append(sgpp).reset_index()


def clean_pharmacies(
    england: Path, scotland: Path, wales: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning pharmacies...&#34;)

    epharm = (
        cudf.read_csv(england, header=None, usecols=[0, 9, 11])
        .rename(columns={&#34;0&#34;: &#34;pharmacy&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;})
        .pipe(lambda x: x[x[&#34;close&#34;].isnull()])
        .drop(&#34;close&#34;, axis=1)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    spharm = (
        cudf.read_csv(scotland, usecols=[0, 6], sep=&#34;\t&#34;)
        .rename(columns={&#34;DispenserCode&#34;: &#34;pharmacy&#34;, &#34;Postcode&#34;: &#34;postcode&#34;})
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    wpharm = (
        cudf.from_pandas(pd.read_excel(wales, usecols=[&#34;Account Number&#34;, &#34;Post Code&#34;]))
        .rename(columns={&#34;Account Number&#34;: &#34;pharmacy&#34;, &#34;Post Code&#34;: &#34;postcode&#34;})
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )
    return epharm.append(spharm).append(wpharm).reset_index()


def clean_hospitals(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    ehos = (
        cudf.read_csv(england, usecols=[0, 9, 11], header=None)
        .rename(columns={&#34;0&#34;: &#34;hospital&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;})
        .pipe(lambda x: x[x[&#34;close&#34;].isnull()])
        .drop(&#34;close&#34;, axis=1)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    shos = (
        cudf.read_csv(scotland, usecols=[&#34;Location&#34;, &#34;Postcode&#34;])
        .rename(columns={&#34;Location&#34;: &#34;hospital&#34;, &#34;Postcode&#34;: &#34;postcode&#34;})
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )
    return ehos.append(shos).reset_index()


def clean_air(path: Path, col: &#34;str&#34;):
    logger.info(f&#34;Cleaning air: {path}:{col}&#34;)
    air: pd.DataFrame = pd.read_csv(path, skiprows=5, header=0)
    air = air[air[col] != &#34;MISSING&#34;]
    air[col] = air[col].astype(float)
    return air


# def clean_greenspace_access(path: Path) -&gt; cudf.DataFrame:
#     logger.info(&#34;Cleaning greenspace access...&#34;)
#     greenspace = gpd.read_file(path)
#     greenspace[&#34;easting&#34;], greenspace[&#34;northing&#34;] = (
#         greenspace.geometry.x,
#         greenspace.geometry.y,
#     )
#     return cudf.DataFrame(greenspace.drop(&#34;geometry&#34;, axis=1)).loc[
#         :, [&#34;id&#34;, &#34;easting&#34;, &#34;northing&#34;]
#     ]


def clean_greenspace_access(england: Path, scotland: Path, wales: Path):
    england = gpd.read_file(england, crs=4326)
    scotland = gpd.read_file(scotland, crs=4326)
    wales = gpd.read_file(wales, crs=4326)
    greenspace = dask_geopandas.from_geopandas(
        wales.append(england).append(scotland), npartitions=os.cpu_count()
    )

    greenspace = greenspace[greenspace[&#34;fclass&#34;] == &#34;path&#34;].to_crs(27700).compute()

    greenspace = (
        greenspace.geometry.boundary.apply(lambda x: x.geoms).explode().dropna()
    )
    greenspace = gpd.GeoDataFrame(greenspace.rename(&#34;geometry&#34;), geometry=&#34;geometry&#34;)
    greenspace[&#34;easting&#34;] = greenspace.geometry.x
    greenspace[&#34;northing&#34;] = greenspace.geometry.y

    greenspace[&#34;easting&#34;] = greenspace[&#34;easting&#34;].round(-2).astype(int)
    greenspace[&#34;northing&#34;] = greenspace[&#34;northing&#34;].round(-2).astype(int)

    return cudf.from_pandas(greenspace[[&#34;easting&#34;, &#34;northing&#34;]]).drop_duplicates()


def single_parametric_interpolate(obj_x_loc, obj_y_loc, num_pts: int):
    # https://stackoverflow.com/questions/42023522/random-sampling-of-points-along-a-polygon-boundary
    if obj_x_loc is None or obj_y_loc is None:
        return None

    num_coords = len(obj_x_loc)

    vi = [
        [
            obj_x_loc[(i + 1) % num_coords] - obj_x_loc[i],
            obj_y_loc[(i + 1) % num_coords] - obj_y_loc[i],
        ]
        for i in range(num_coords)
    ]
    si = [np.linalg.norm(v) for v in vi]
    di = np.linspace(0, sum(si), num_pts, endpoint=False)
    new_points = []
    for d in di:
        for i, s in enumerate(si):
            if d &gt; s:
                d -= s
            else:
                break
        lnth = d / s
        new_points.append(
            [int(obj_x_loc[i] + lnth * vi[i][0]), int(obj_y_loc[i] + lnth * vi[i][1])]
        )
    return new_points


def catch_exterior(row):
    return row.exterior.coords.xy if isinstance(row, Polygon) else None


def clean_bluespace(data_dir: Path) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning bluespace...&#34;)
    bluespace = gpd.GeoDataFrame(
        pd.concat(
            [gpd.read_file(shp) for shp in tqdm(list(data_dir.glob(&#34;*.shp&#34;)))],
            ignore_index=True,
        )
    )

    high_water = bluespace[bluespace[&#34;CLASSIFICA&#34;] == &#34;High Water Mark&#34;]
    bluespace = bluespace[(bluespace.geometry.area &gt; 10_000)]
    bluespace.geometry = bluespace.geometry.simplify(25)
    high_water.geometry = high_water.geometry.simplify(25)

    tqdm.pandas()
    high_water = high_water.progress_apply(lambda x: x.geometry.coords.xy, axis=1)
    bluespace = bluespace.progress_apply(
        lambda x: catch_exterior(x.geometry), axis=1
    ).dropna()
    bluespace = bluespace.append(high_water)
    bluespace = pd.DataFrame(bluespace.tolist())

    tqdm.pandas()
    bluespace = cudf.DataFrame(
        bluespace.progress_apply(
            lambda row: single_parametric_interpolate(row[0], row[1], num_pts=10),
            axis=1,
        )
        .explode()
        .dropna()
        .tolist(),
        columns=[&#34;easting&#34;, &#34;northing&#34;],
    )

    bluespace[&#34;easting&#34;] = bluespace[&#34;easting&#34;].round(-2)
    bluespace[&#34;northing&#34;] = bluespace[&#34;northing&#34;].round(-2)

    return bluespace.drop_duplicates()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ahah.common.utils.catch_exterior"><code class="name flex">
<span>def <span class="ident">catch_exterior</span></span>(<span>row)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def catch_exterior(row):
    return row.exterior.coords.xy if isinstance(row, Polygon) else None</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_air"><code class="name flex">
<span>def <span class="ident">clean_air</span></span>(<span>path: pathlib.Path, col: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_air(path: Path, col: &#34;str&#34;):
    logger.info(f&#34;Cleaning air: {path}:{col}&#34;)
    air: pd.DataFrame = pd.read_csv(path, skiprows=5, header=0)
    air = air[air[col] != &#34;MISSING&#34;]
    air[col] = air[col].astype(float)
    return air</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_bluespace"><code class="name flex">
<span>def <span class="ident">clean_bluespace</span></span>(<span>data_dir: pathlib.Path) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_bluespace(data_dir: Path) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning bluespace...&#34;)
    bluespace = gpd.GeoDataFrame(
        pd.concat(
            [gpd.read_file(shp) for shp in tqdm(list(data_dir.glob(&#34;*.shp&#34;)))],
            ignore_index=True,
        )
    )

    high_water = bluespace[bluespace[&#34;CLASSIFICA&#34;] == &#34;High Water Mark&#34;]
    bluespace = bluespace[(bluespace.geometry.area &gt; 10_000)]
    bluespace.geometry = bluespace.geometry.simplify(25)
    high_water.geometry = high_water.geometry.simplify(25)

    tqdm.pandas()
    high_water = high_water.progress_apply(lambda x: x.geometry.coords.xy, axis=1)
    bluespace = bluespace.progress_apply(
        lambda x: catch_exterior(x.geometry), axis=1
    ).dropna()
    bluespace = bluespace.append(high_water)
    bluespace = pd.DataFrame(bluespace.tolist())

    tqdm.pandas()
    bluespace = cudf.DataFrame(
        bluespace.progress_apply(
            lambda row: single_parametric_interpolate(row[0], row[1], num_pts=10),
            axis=1,
        )
        .explode()
        .dropna()
        .tolist(),
        columns=[&#34;easting&#34;, &#34;northing&#34;],
    )

    bluespace[&#34;easting&#34;] = bluespace[&#34;easting&#34;].round(-2)
    bluespace[&#34;northing&#34;] = bluespace[&#34;northing&#34;].round(-2)

    return bluespace.drop_duplicates()</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_dentists"><code class="name flex">
<span>def <span class="ident">clean_dentists</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_dentists(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning dentists...&#34;)

    edent = (
        cudf.read_csv(england, usecols=[0, 9], header=None)
        .rename(columns={&#34;0&#34;: &#34;dentist&#34;, &#34;9&#34;: &#34;postcode&#34;})
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    sdent = (
        cudf.read_csv(scotland)
        .rename(
            columns={
                &#34;﻿DentalPracticeCode&#34;: &#34;dentist&#34;,
                &#34;Postcode&#34;: &#34;postcode&#34;,
            }
        )[[&#34;dentist&#34;, &#34;postcode&#34;]]
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    return edent.append(sdent).reset_index()</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_gpp"><code class="name flex">
<span>def <span class="ident">clean_gpp</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_gpp(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning gpp...&#34;)

    egpp = (
        cudf.read_csv(england, usecols=[0, 9, 11], header=None)
        .rename(columns={&#34;0&#34;: &#34;gpp&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;})
        .pipe(lambda x: x[x[&#34;close&#34;].isna()])
        .drop(&#34;close&#34;, axis=1)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    sgpp = (
        cudf.read_csv(scotland, usecols=[&#34;PracticeCode&#34;, &#34;Postcode&#34;])
        .rename(columns={&#34;PracticeCode&#34;: &#34;gpp&#34;, &#34;Postcode&#34;: &#34;postcode&#34;})
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    return egpp.append(sgpp).reset_index()</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_greenspace_access"><code class="name flex">
<span>def <span class="ident">clean_greenspace_access</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, wales: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_greenspace_access(england: Path, scotland: Path, wales: Path):
    england = gpd.read_file(england, crs=4326)
    scotland = gpd.read_file(scotland, crs=4326)
    wales = gpd.read_file(wales, crs=4326)
    greenspace = dask_geopandas.from_geopandas(
        wales.append(england).append(scotland), npartitions=os.cpu_count()
    )

    greenspace = greenspace[greenspace[&#34;fclass&#34;] == &#34;path&#34;].to_crs(27700).compute()

    greenspace = (
        greenspace.geometry.boundary.apply(lambda x: x.geoms).explode().dropna()
    )
    greenspace = gpd.GeoDataFrame(greenspace.rename(&#34;geometry&#34;), geometry=&#34;geometry&#34;)
    greenspace[&#34;easting&#34;] = greenspace.geometry.x
    greenspace[&#34;northing&#34;] = greenspace.geometry.y

    greenspace[&#34;easting&#34;] = greenspace[&#34;easting&#34;].round(-2).astype(int)
    greenspace[&#34;northing&#34;] = greenspace[&#34;northing&#34;].round(-2).astype(int)

    return cudf.from_pandas(greenspace[[&#34;easting&#34;, &#34;northing&#34;]]).drop_duplicates()</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_hospitals"><code class="name flex">
<span>def <span class="ident">clean_hospitals</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_hospitals(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    ehos = (
        cudf.read_csv(england, usecols=[0, 9, 11], header=None)
        .rename(columns={&#34;0&#34;: &#34;hospital&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;})
        .pipe(lambda x: x[x[&#34;close&#34;].isnull()])
        .drop(&#34;close&#34;, axis=1)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    shos = (
        cudf.read_csv(scotland, usecols=[&#34;Location&#34;, &#34;Postcode&#34;])
        .rename(columns={&#34;Location&#34;: &#34;hospital&#34;, &#34;Postcode&#34;: &#34;postcode&#34;})
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )
    return ehos.append(shos).reset_index()</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_pharmacies"><code class="name flex">
<span>def <span class="ident">clean_pharmacies</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, wales: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_pharmacies(
    england: Path, scotland: Path, wales: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning pharmacies...&#34;)

    epharm = (
        cudf.read_csv(england, header=None, usecols=[0, 9, 11])
        .rename(columns={&#34;0&#34;: &#34;pharmacy&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;})
        .pipe(lambda x: x[x[&#34;close&#34;].isnull()])
        .drop(&#34;close&#34;, axis=1)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    spharm = (
        cudf.read_csv(scotland, usecols=[0, 6], sep=&#34;\t&#34;)
        .rename(columns={&#34;DispenserCode&#34;: &#34;pharmacy&#34;, &#34;Postcode&#34;: &#34;postcode&#34;})
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )

    wpharm = (
        cudf.from_pandas(pd.read_excel(wales, usecols=[&#34;Account Number&#34;, &#34;Post Code&#34;]))
        .rename(columns={&#34;Account Number&#34;: &#34;pharmacy&#34;, &#34;Post Code&#34;: &#34;postcode&#34;})
        .astype(str)
        .pipe(fix_postcodes)
        .set_index(&#34;postcode&#34;)
        .join(postcodes)
        .pipe(find_partial_pc, postcodes)
    )
    return epharm.append(spharm).append(wpharm).reset_index()</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.clean_postcodes"><code class="name flex">
<span>def <span class="ident">clean_postcodes</span></span>(<span>path: pathlib.Path, current: bool) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_postcodes(path: Path, current: bool) -&gt; cudf.DataFrame:
    logger.info(&#34;Cleaning postcodes...&#34;)

    dtypes = {
        &#34;pcd&#34;: &#34;str&#34;,
        &#34;lsoa11&#34;: &#34;str&#34;,
        &#34;oseast1m&#34;: &#34;int&#34;,
        &#34;osnrth1m&#34;: &#34;int&#34;,
        &#34;doterm&#34;: &#34;int&#34;,
        &#34;ctry&#34;: &#34;str&#34;,
    }
    column_names = {
        &#34;pcd&#34;: &#34;postcode&#34;,
        &#34;oseast1m&#34;: &#34;easting&#34;,
        &#34;osnrth1m&#34;: &#34;northing&#34;,
    }

    postcodes = (
        cudf.read_csv(
            path,
            usecols=[*dtypes],
            dtype=dtypes,
        )
        .rename(columns=column_names)
        .set_index(&#34;ctry&#34;)
        .loc[[&#34;E92000001&#34;, &#34;S92000003&#34;, &#34;W92000004&#34;]]
        .pipe(fix_postcodes)
        .dropna(subset=[&#34;northing&#34;, &#34;easting&#34;])
        .set_index(&#34;postcode&#34;)
        .drop_duplicates()
    )

    if not current:
        return postcodes.drop(&#34;doterm&#34;, axis=1)

    # 2 scottish LSOA have no current postcodes - so use nearby ones
    pc_current = postcodes[postcodes[&#34;doterm&#34;].isnull()]
    missing = postcodes.copy()
    missing.loc[&#34;G21 4QJ&#34;, &#34;lsoa11&#34;] = &#34;S01010206&#34;
    missing.loc[[&#34;G21 1NL&#34;, &#34;G21 1RR&#34;], &#34;lsoa11&#34;] = &#34;S01010226&#34;

    return (
        pc_current.append(postcodes[postcodes[&#34;lsoa11&#34;] == &#34;S01011827&#34;])
        .append(missing.loc[[&#34;G21 4QJ&#34;, &#34;G21 1NL&#34;, &#34;G21 1RR&#34;]])
        .drop(&#34;doterm&#34;, axis=1)
    )</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.combine_lsoa"><code class="name flex">
<span>def <span class="ident">combine_lsoa</span></span>(<span>eng, scot, wales)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine_lsoa(eng, scot, wales):
    eng = gpd.read_file(eng)[[&#34;code&#34;, &#34;name&#34;, &#34;geometry&#34;]].rename(
        columns={&#34;code&#34;: &#34;lsoa11&#34;}
    )
    scot = gpd.read_file(scot)[[&#34;DataZone&#34;, &#34;Name&#34;, &#34;geometry&#34;]].rename(
        columns={&#34;DataZone&#34;: &#34;lsoa11&#34;, &#34;Name&#34;: &#34;name&#34;}
    )
    wales = gpd.read_file(wales)[[&#34;LSOA11Code&#34;, &#34;lsoa11name&#34;, &#34;geometry&#34;]].rename(
        columns={&#34;LSOA11Code&#34;: &#34;lsoa11&#34;, &#34;lsoa11name&#34;: &#34;name&#34;}
    )
    return eng.append(scot).append(wales)</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.find_partial_pc"><code class="name flex">
<span>def <span class="ident">find_partial_pc</span></span>(<span>df, postcodes)</span>
</code></dt>
<dd>
<div class="desc"><p>Find postcodes that have partially correct first characters.</p>
<p>Splits postcodes into two and uses first half to match to likely nearest
correct postcode location if the postcode cannot be found in whole postcode
dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>poi</code></strong> :&ensp;<code>Union[pd.DataFrame, cudf.DataFrame]</code></dt>
<dd>POI dataframe containing series of postcodes</dd>
<dt><strong><code>poi_pc</code></strong> :&ensp;<code>Union[pd.DataFrame, cudf.DataFrame]</code></dt>
<dd>POI dataframe with df postcodes</dd>
<dt><strong><code>postcodes</code></strong> :&ensp;<code>Union[pd.DataFrame, cudf.DataFrame]</code></dt>
<dd>Dataframe of all postcodes</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[pd.DataFrame, cudf.DataFrame]:</code></dt>
<dd>POI dataframe with inferred postcodes</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_partial_pc(df, postcodes):
    &#34;&#34;&#34;
    Find postcodes that have partially correct first characters.

    Splits postcodes into two and uses first half to match to likely nearest
    correct postcode location if the postcode cannot be found in whole postcode
    dataset.

    Parameters
    ----------
    poi : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe containing series of postcodes
    poi_pc : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe with df postcodes
    postcodes : Union[pd.DataFrame, cudf.DataFrame]
        Dataframe of all postcodes
    Returns
    -------
    Union[pd.DataFrame, cudf.DataFrame]:
        POI dataframe with inferred postcodes
    &#34;&#34;&#34;
    remove_pcs = &#34;|&#34;.join([&#34;GY&#34;, &#34;JE&#34;, &#34;IM&#34;, &#34;BF&#34;])

    df = df[~df.index.str.contains(remove_pcs).values]
    missing = df[df[&#34;easting&#34;].isna()].reset_index()
    postcodes = postcodes.reset_index()

    missing[&#34;partial&#34;] = missing[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]
    postcodes[&#34;partial&#34;] = postcodes[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]

    missing = missing.set_index(&#34;partial&#34;).drop(
        [&#34;postcode&#34;, &#34;easting&#34;, &#34;northing&#34;], axis=1
    )
    postcodes = postcodes.set_index(&#34;partial&#34;)

    missing = (
        missing.join(postcodes)
        .reset_index()
        .drop_duplicates(&#34;partial&#34;)
        .drop(&#34;partial&#34;, axis=1)
        .set_index(&#34;postcode&#34;)
        .dropna()
    )

    return df.dropna().append(missing)</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.fix_postcodes"><code class="name flex">
<span>def <span class="ident">fix_postcodes</span></span>(<span>df: Union[pandas.core.frame.DataFrame, cudf.core.dataframe.DataFrame]) ‑> Union[pandas.core.frame.DataFrame, cudf.core.dataframe.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Ensure all postcodes follow correct spacing format</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>series</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>Df with Series of postcodes as strings</dd>
</dl>
<h2 id="returns">Returns</h2>
<h2 id="dataframe">Dataframe</h2>
<p>Df with correctly formatted series of postcodes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fix_postcodes(df: DataFrame) -&gt; DataFrame:
    &#34;&#34;&#34;
    Ensure all postcodes follow correct spacing format

    Parameters
    ----------
    series : DataFrame
        Df with Series of postcodes as strings

    Returns
    -------
    DataFrame:
        Df with correctly formatted series of postcodes
    &#34;&#34;&#34;
    df[&#34;postcode&#34;] = df[&#34;postcode&#34;].str.replace(&#34; &#34;, &#34;&#34;)
    df[&#34;postcode&#34;] = df[&#34;postcode&#34;].str[:-3] + &#34; &#34; + df[&#34;postcode&#34;].str[-3:]
    return df</code></pre>
</details>
</dd>
<dt id="ahah.common.utils.single_parametric_interpolate"><code class="name flex">
<span>def <span class="ident">single_parametric_interpolate</span></span>(<span>obj_x_loc, obj_y_loc, num_pts: int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def single_parametric_interpolate(obj_x_loc, obj_y_loc, num_pts: int):
    # https://stackoverflow.com/questions/42023522/random-sampling-of-points-along-a-polygon-boundary
    if obj_x_loc is None or obj_y_loc is None:
        return None

    num_coords = len(obj_x_loc)

    vi = [
        [
            obj_x_loc[(i + 1) % num_coords] - obj_x_loc[i],
            obj_y_loc[(i + 1) % num_coords] - obj_y_loc[i],
        ]
        for i in range(num_coords)
    ]
    si = [np.linalg.norm(v) for v in vi]
    di = np.linspace(0, sum(si), num_pts, endpoint=False)
    new_points = []
    for d in di:
        for i, s in enumerate(si):
            if d &gt; s:
                d -= s
            else:
                break
        lnth = d / s
        new_points.append(
            [int(obj_x_loc[i] + lnth * vi[i][0]), int(obj_y_loc[i] + lnth * vi[i][1])]
        )
    return new_points</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ahah.common.utils.Config"><code class="flex name class">
<span>class <span class="ident">Config</span></span>
</code></dt>
<dd>
<div class="desc"><p>Misc constants required throughout</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Config:
    &#34;&#34;&#34;Misc constants required throughout&#34;&#34;&#34;

    DATA_PATH = Path(os.environ[&#34;PROJECT_ROOT&#34;]) / &#34;data&#34;
    RAW_DATA = DATA_PATH / &#34;raw&#34;
    PROCESSED_DATA = DATA_PATH / &#34;processed&#34;
    OUT_DATA = DATA_PATH / &#34;out&#34;
    OS_GRAPH = PROCESSED_DATA / &#34;osm&#34;
    HW_DATA = RAW_DATA / &#34;os_highways&#34; / &#34;oproad_gb.gpkg&#34;

    POI_LIST = [
        &#34;gpp&#34;,
        &#34;dentists&#34;,
        &#34;pharmacies&#34;,
        &#34;hospitals&#34;,
        &#34;greenspace&#34;,
        &#34;bluespace&#34;,
    ]

    NODE_COLS = [&#34;node_id&#34;, &#34;easting&#34;, &#34;northing&#34;]
    EDGE_COLS = [&#34;source&#34;, &#34;target&#34;, &#34;time_weighted&#34;, &#34;length&#34;]

    # WARN:In final version find out exact dates and update Scotland to newest.
    # https://digital.nhs.uk/services/organisation-data-service/data-downloads
    NHS_URL = &#34;https://files.digital.nhs.uk/assets/ods/current/&#34;
    NHS_FILES = {
        # 25 Feburary 2022 - Checked 22 March 2022
        &#34;gpp&#34;: &#34;epraccur.zip&#34;,
        # &#34;&#34;
        &#34;dentists&#34;: &#34;egdpprac.zip&#34;,
        # &#34;&#34;
        &#34;pharmacies&#34;: &#34;edispensary.zip&#34;,
        # &#34;&#34;
        &#34;hospitals&#34;: &#34;ets.zip&#34;,
    }
    NHS_SCOT_URL = &#34;https://www.opendata.nhs.scot/dataset/&#34;
    NHS_SCOT_FILES = {
        # GP Practices and List sizes Jan 2022
        &#34;gpp&#34;: &#34;f23655c3-6e23-4103-a511-a80d998adb90/resource&#34;
        &#34;/a794d603-95ab-4309-8c92-b48970478c14/download&#34;
        &#34;/practice_contactdetails_jan2022.csv&#34;,
        # Dental Practices June 2021
        &#34;dentists&#34;: &#34;2f218ba7-6695-4b22-867d-41383ae36de7/resource&#34;
        &#34;/12bf4b02-15e6-41d0-9ae0-18663b463833/download&#34;
        &#34;/nhs-dental-practices-and-nhs-dental-registrations-as-at-30th-june-2021.csv&#34;,
        # Current NHS Hospitals in Scotland 16th December 2021
        &#34;hospitals&#34;: &#34;cbd1802e-0e04-4282-88eb-d7bdcfb120f0/resource&#34;
        &#34;/c698f450-eeed-41a0-88f7-c1e40a568acc/download&#34;
        &#34;/current-hospital_flagged20211216.csv&#34;,
        # Dispenser Details October 2021
        &#34;pharmacies&#34;: &#34;a30fde16-1226-49b3-b13d-eb90e39c2058/resource&#34;
        &#34;/9f9db0c9-8b5a-4813-b586-7e0084bbf9b0/download&#34;
        &#34;/dispenser_contactdetails_oct2021.csv&#34;,
    }
    NHS_WALES_URL = (
        &#34;https://nwssp.nhs.wales/ourservices/&#34;
        &#34;primary-care-services/primary-care-services-documents/&#34;
    )
    NHS_WALES_FILES = {
        &#34;pharmacy&#34;: (
            &#34;pharmacy-practice-dispensing-data-docs&#34;
            &#34;/dispensing-data-report-november-2021&#34;
        )
    }</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="ahah.common.utils.Config.DATA_PATH"><code class="name">var <span class="ident">DATA_PATH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.EDGE_COLS"><code class="name">var <span class="ident">EDGE_COLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.HW_DATA"><code class="name">var <span class="ident">HW_DATA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.NHS_FILES"><code class="name">var <span class="ident">NHS_FILES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.NHS_SCOT_FILES"><code class="name">var <span class="ident">NHS_SCOT_FILES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.NHS_SCOT_URL"><code class="name">var <span class="ident">NHS_SCOT_URL</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.NHS_URL"><code class="name">var <span class="ident">NHS_URL</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.NHS_WALES_FILES"><code class="name">var <span class="ident">NHS_WALES_FILES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.NHS_WALES_URL"><code class="name">var <span class="ident">NHS_WALES_URL</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.NODE_COLS"><code class="name">var <span class="ident">NODE_COLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.OS_GRAPH"><code class="name">var <span class="ident">OS_GRAPH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.OUT_DATA"><code class="name">var <span class="ident">OUT_DATA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.POI_LIST"><code class="name">var <span class="ident">POI_LIST</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.PROCESSED_DATA"><code class="name">var <span class="ident">PROCESSED_DATA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.common.utils.Config.RAW_DATA"><code class="name">var <span class="ident">RAW_DATA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ahah.common" href="index.html">ahah.common</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ahah.common.utils.catch_exterior" href="#ahah.common.utils.catch_exterior">catch_exterior</a></code></li>
<li><code><a title="ahah.common.utils.clean_air" href="#ahah.common.utils.clean_air">clean_air</a></code></li>
<li><code><a title="ahah.common.utils.clean_bluespace" href="#ahah.common.utils.clean_bluespace">clean_bluespace</a></code></li>
<li><code><a title="ahah.common.utils.clean_dentists" href="#ahah.common.utils.clean_dentists">clean_dentists</a></code></li>
<li><code><a title="ahah.common.utils.clean_gpp" href="#ahah.common.utils.clean_gpp">clean_gpp</a></code></li>
<li><code><a title="ahah.common.utils.clean_greenspace_access" href="#ahah.common.utils.clean_greenspace_access">clean_greenspace_access</a></code></li>
<li><code><a title="ahah.common.utils.clean_hospitals" href="#ahah.common.utils.clean_hospitals">clean_hospitals</a></code></li>
<li><code><a title="ahah.common.utils.clean_pharmacies" href="#ahah.common.utils.clean_pharmacies">clean_pharmacies</a></code></li>
<li><code><a title="ahah.common.utils.clean_postcodes" href="#ahah.common.utils.clean_postcodes">clean_postcodes</a></code></li>
<li><code><a title="ahah.common.utils.combine_lsoa" href="#ahah.common.utils.combine_lsoa">combine_lsoa</a></code></li>
<li><code><a title="ahah.common.utils.find_partial_pc" href="#ahah.common.utils.find_partial_pc">find_partial_pc</a></code></li>
<li><code><a title="ahah.common.utils.fix_postcodes" href="#ahah.common.utils.fix_postcodes">fix_postcodes</a></code></li>
<li><code><a title="ahah.common.utils.single_parametric_interpolate" href="#ahah.common.utils.single_parametric_interpolate">single_parametric_interpolate</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ahah.common.utils.Config" href="#ahah.common.utils.Config">Config</a></code></h4>
<ul class="two-column">
<li><code><a title="ahah.common.utils.Config.DATA_PATH" href="#ahah.common.utils.Config.DATA_PATH">DATA_PATH</a></code></li>
<li><code><a title="ahah.common.utils.Config.EDGE_COLS" href="#ahah.common.utils.Config.EDGE_COLS">EDGE_COLS</a></code></li>
<li><code><a title="ahah.common.utils.Config.HW_DATA" href="#ahah.common.utils.Config.HW_DATA">HW_DATA</a></code></li>
<li><code><a title="ahah.common.utils.Config.NHS_FILES" href="#ahah.common.utils.Config.NHS_FILES">NHS_FILES</a></code></li>
<li><code><a title="ahah.common.utils.Config.NHS_SCOT_FILES" href="#ahah.common.utils.Config.NHS_SCOT_FILES">NHS_SCOT_FILES</a></code></li>
<li><code><a title="ahah.common.utils.Config.NHS_SCOT_URL" href="#ahah.common.utils.Config.NHS_SCOT_URL">NHS_SCOT_URL</a></code></li>
<li><code><a title="ahah.common.utils.Config.NHS_URL" href="#ahah.common.utils.Config.NHS_URL">NHS_URL</a></code></li>
<li><code><a title="ahah.common.utils.Config.NHS_WALES_FILES" href="#ahah.common.utils.Config.NHS_WALES_FILES">NHS_WALES_FILES</a></code></li>
<li><code><a title="ahah.common.utils.Config.NHS_WALES_URL" href="#ahah.common.utils.Config.NHS_WALES_URL">NHS_WALES_URL</a></code></li>
<li><code><a title="ahah.common.utils.Config.NODE_COLS" href="#ahah.common.utils.Config.NODE_COLS">NODE_COLS</a></code></li>
<li><code><a title="ahah.common.utils.Config.OS_GRAPH" href="#ahah.common.utils.Config.OS_GRAPH">OS_GRAPH</a></code></li>
<li><code><a title="ahah.common.utils.Config.OUT_DATA" href="#ahah.common.utils.Config.OUT_DATA">OUT_DATA</a></code></li>
<li><code><a title="ahah.common.utils.Config.POI_LIST" href="#ahah.common.utils.Config.POI_LIST">POI_LIST</a></code></li>
<li><code><a title="ahah.common.utils.Config.PROCESSED_DATA" href="#ahah.common.utils.Config.PROCESSED_DATA">PROCESSED_DATA</a></code></li>
<li><code><a title="ahah.common.utils.Config.RAW_DATA" href="#ahah.common.utils.Config.RAW_DATA">RAW_DATA</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>