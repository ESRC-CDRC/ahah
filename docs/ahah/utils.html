<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ahah.utils API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ahah.utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import itertools
from pathlib import Path
from typing import Union

import cudf
import geopandas as gpd
import pandas as pd
from shapely.geometry import mapping


class Config:
    &#34;&#34;&#34;Misc constants required throughout&#34;&#34;&#34;

    DATA_PATH = Path(&#34;data/&#34;)
    RAW_DATA = DATA_PATH / &#34;raw&#34;
    PROCESSED_DATA = DATA_PATH / &#34;processed&#34;
    OUT_DATA = DATA_PATH / &#34;out&#34;
    OSM_GRAPH = PROCESSED_DATA / &#34;osm&#34;

    POI_LIST = [
        &#34;gpp&#34;,
        &#34;dentists&#34;,
        &#34;pharmacies&#34;,
        &#34;hospitals&#34;,
        &#34;greenspace&#34;,
        &#34;bluespace&#34;,
    ]

    NODE_COLS = [&#34;node_id&#34;, &#34;easting&#34;, &#34;northing&#34;]
    EDGE_COLS = [&#34;source&#34;, &#34;target&#34;, &#34;time_weighted&#34;, &#34;length&#34;]

    # https://digital.nhs.uk/services/organisation-data-service/data-downloads
    # A&amp;E from https://www.england.nhs.uk/statistics/statistical-work-areas/ae-waiting-times-and-activity/ae-attendances-and-emergency-admissions-2020-21/
    NHS_URL = &#34;https://files.digital.nhs.uk/assets/ods/current/&#34;
    NHS_FILES = {
        # 26 February 2021
        &#34;gpp&#34;: &#34;epraccur.zip&#34;,
        # 26 February 2021
        &#34;dentists&#34;: &#34;egdpprac.zip&#34;,
        # 26 February 2021
        &#34;pharmacies&#34;: &#34;epharmacyhq.zip&#34;,
        # 25 February 2021
        &#34;hospitals&#34;: &#34;ets.zip&#34;,
    }
    NHS_SCOT_URL = &#34;https://www.opendata.nhs.scot/dataset/&#34;
    NHS_SCOT = {
        # GP Practices and List sizes April 2021
        &#34;gpp&#34;: &#34;f23655c3-6e23-4103-a511-a80d998adb90/resource&#34;
        &#34;/a794d603-95ab-4309-8c92-b48970478c14/download&#34;
        &#34;/practice_contactdetails_apr2021-open-data.csv&#34;,
        # Dental Practices December 2020
        &#34;dentists&#34;: &#34;2f218ba7-6695-4b22-867d-41383ae36de7/resource&#34;
        &#34;/20040f9f-e598-4237-8a12-8bc35c0b2959/download&#34;
        &#34;/nhs-dental-practices-and-nhs-dental-registrations-as-at-31st-december-2020.csv&#34;,
        # Current NHS Hospitals in Scotland 6th May, 2021
        &#34;hospitals&#34;: &#34;cbd1802e-0e04-4282-88eb-d7bdcfb120f0/resource&#34;
        &#34;/c698f450-eeed-41a0-88f7-c1e40a568acc/download&#34;
        &#34;/current-hospital_flagged20210506.csv&#34;,
        # Accident &amp; Emergency Sites 9th April, 2020
        &#34;ae&#34;: &#34;a877470a-06a9-492f-b9e8-992f758894d0/resource&#34;
        &#34;/1a4e3f48-3d9b-4769-80e9-3ef6d27852fe/download&#34;
        &#34;/hospital_site_list.csv&#34;,
        # Dispenser Details October 2020
        &#34;pharmacies&#34;: &#34;a30fde16-1226-49b3-b13d-eb90e39c2058/resource&#34;
        &#34;/d08bc753-c6dc-4dbd-8b37-ef439d3a7428/download&#34;
        &#34;/dispenser_contactdetails_oct2020_notabs.csv&#34;,
    }


def fix_postcodes(
    series: Union[pd.Series, cudf.Series]
) -&gt; Union[pd.Series, cudf.Series]:
    &#34;&#34;&#34;
    Ensure all postcodes follow correct spacing format

    Parameters
    ----------
    series : Union[pd.Series, cudf.Series]
        Series of postcodes as strings

    Returns
    -------
    Union[pd.Series, cudf.Series]:
        Correctly formatted series of postcodes
    &#34;&#34;&#34;
    series = series.str.replace(&#34; &#34;, &#34;&#34;)
    series = series.str[:-3] + &#34; &#34; + series.str[-3:]
    return series


def find_partial_pc(
    poi: Union[pd.DataFrame, cudf.DataFrame],
    poi_pc: Union[pd.DataFrame, cudf.DataFrame],
    postcodes: Union[pd.DataFrame, cudf.DataFrame],
) -&gt; Union[pd.DataFrame, cudf.DataFrame]:
    &#34;&#34;&#34;
    Find postcodes that have partially correct first characters

    Splits postcodes into two and uses first half to match to likely nearest
    correct postcode location if the postcode cannot be found in whole postcode
    dataset.

    Parameters
    ----------
    poi : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe containing series of postcodes
    poi_pc : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe with missing postcodes
    postcodes : Union[pd.DataFrame, cudf.DataFrame]
        Dataframe of all postcodes

    Returns
    -------
    Union[pd.DataFrame, cudf.DataFrame]:
        POI dataframe with inferred postcodes
    &#34;&#34;&#34;
    # find approximate location of incorrect postcodes
    missing = poi[~poi[&#34;postcode&#34;].isin(poi_pc[&#34;postcode&#34;])]
    missing[&#34;partial&#34;] = missing[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]
    postcodes[&#34;partial&#34;] = postcodes[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]
    poi_pc = poi_pc.append(
        missing.merge(
            postcodes[[&#34;partial&#34;, &#34;easting&#34;, &#34;northing&#34;]], on=&#34;partial&#34;
        ).drop_duplicates(&#34;partial&#34;)
    ).drop(&#34;partial&#34;, axis=1)
    postcodes.drop(&#34;partial&#34;, axis=1, inplace=True)
    return poi_pc


def clean_postcodes(
    path: Path, current: bool, scotland=True, wales=True
) -&gt; cudf.DataFrame:
    postcodes = cudf.read_csv(
        path,
        usecols=[&#34;pcd&#34;, &#34;oseast1m&#34;, &#34;osnrth1m&#34;, &#34;doterm&#34;, &#34;ctry&#34;],
        dtype={
            &#34;pcd&#34;: &#34;str&#34;,
            &#34;oseast1m&#34;: &#34;int&#34;,
            &#34;osnrth1m&#34;: &#34;int&#34;,
            &#34;doterm&#34;: &#34;str&#34;,
            &#34;ctry&#34;: &#34;str&#34;,
        },
    )
    countries = [&#34;E92000001&#34;]
    if scotland:
        countries.append(&#34;S92000003&#34;)
    if wales:
        countries.append(&#34;W92000004&#34;)

    postcodes = postcodes[postcodes[&#34;ctry&#34;].isin(countries)].drop(&#34;ctry&#34;, axis=1)

    postcodes = postcodes.rename(
        columns={&#34;pcd&#34;: &#34;postcode&#34;, &#34;oseast1m&#34;: &#34;easting&#34;, &#34;osnrth1m&#34;: &#34;northing&#34;}
    )
    postcodes[&#34;postcode&#34;] = fix_postcodes(postcodes[&#34;postcode&#34;])
    postcodes = postcodes.dropna(subset=[&#34;easting&#34;, &#34;northing&#34;])

    if current:
        return postcodes[postcodes[&#34;doterm&#34;].isnull()].drop(&#34;doterm&#34;, axis=1)
    return postcodes.drop(&#34;doterm&#34;, axis=1)


def clean_dentists(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    edent = cudf.read_csv(england, usecols=[0, 9], header=None)
    edent.rename(columns={&#34;0&#34;: &#34;dentist&#34;, &#34;9&#34;: &#34;postcode&#34;}, inplace=True)
    edent[&#34;postcode&#34;] = fix_postcodes(edent[&#34;postcode&#34;])
    # remove isle of man pc
    edent = edent[~edent[&#34;postcode&#34;].str.startswith(&#34;IM&#34;)]
    edent_pc = edent.merge(postcodes, on=&#34;postcode&#34;)

    sdent = cudf.read_csv(scotland, usecols=[&#34;DentalPracticeCode&#34;, &#34;Postcode&#34;])
    sdent.rename(
        columns={&#34;DentalPracticeCode&#34;: &#34;dentist&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True
    )
    sdent[&#34;dentist&#34;] = sdent[&#34;dentist&#34;].astype(str)
    sdent[&#34;postcode&#34;] = fix_postcodes(sdent[&#34;postcode&#34;])
    sdent_pc = sdent.merge(postcodes, on=&#34;postcode&#34;)
    sdent_pc = find_partial_pc(sdent, sdent_pc, postcodes)

    assert len(edent) == len(edent_pc), &#34;Missing UK dentist postcodes&#34;
    assert len(sdent) == len(sdent_pc), &#34;Missing Scotland dentist postcodes&#34;
    return edent_pc.append(sdent_pc)


def clean_gpp(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    egpp = cudf.read_csv(england, usecols=[0, 9, 11], header=None)
    egpp.rename(columns={&#34;0&#34;: &#34;gpp&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;}, inplace=True)

    # remove alderney + gurnsey + jersey + isle of man + british forces + closed hospitals
    egpp = egpp[egpp[&#34;close&#34;].isnull()][[&#34;gpp&#34;, &#34;postcode&#34;]].drop_duplicates()
    egpp[&#34;postcode&#34;] = fix_postcodes(egpp[&#34;postcode&#34;])
    egpp = egpp[
        ~egpp[&#34;gpp&#34;].str.startswith(&#34;ALD&#34;)
        &amp; ~egpp[&#34;gpp&#34;].str.startswith(&#34;GUE&#34;)
        &amp; ~egpp[&#34;gpp&#34;].str.startswith(&#34;JER&#34;)
    ]
    egpp = egpp[
        ~egpp[&#34;postcode&#34;].str.startswith(&#34;IM&#34;) &amp; ~egpp[&#34;postcode&#34;].str.startswith(&#34;BF&#34;)
    ]

    egpp_pc = egpp.merge(postcodes, on=&#34;postcode&#34;)
    egpp_pc = find_partial_pc(egpp, egpp_pc, postcodes)
    # fix one mistyped welsh postcode
    egpp_pc = egpp_pc.append(postcodes[postcodes[&#34;postcode&#34;] == &#34;LL55 1HU&#34;])

    sgpp = cudf.read_csv(scotland, usecols=[&#34;PracticeCode&#34;, &#34;Postcode&#34;])
    sgpp.rename(columns={&#34;PracticeCode&#34;: &#34;gpp&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True)
    sgpp[&#34;gpp&#34;] = sgpp[&#34;gpp&#34;].astype(str)
    sgpp[&#34;postcode&#34;] = fix_postcodes(sgpp[&#34;postcode&#34;])
    sgpp_pc = sgpp.merge(postcodes, on=&#34;postcode&#34;)

    assert len(egpp) == len(egpp_pc), &#34;Missing UK gpp postcodes&#34;
    assert len(sgpp) == len(sgpp_pc), &#34;Missing Scotland gpp postcodes&#34;
    return egpp_pc.append(sgpp_pc)


def clean_pharmacies(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    epharm = cudf.read_csv(england, header=None, usecols=[0, 9, 11])
    epharm.rename(
        columns={&#34;0&#34;: &#34;pharmacy&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;}, inplace=True
    )

    # remove closed + isle of man
    epharm = epharm[epharm[&#34;close&#34;].isnull()][
        [&#34;pharmacy&#34;, &#34;postcode&#34;]
    ].drop_duplicates()
    epharm[&#34;postcode&#34;] = fix_postcodes(epharm[&#34;postcode&#34;])
    epharm = epharm[~epharm[&#34;postcode&#34;].str.startswith(&#34;IM&#34;)]
    epharm_pc = epharm.merge(postcodes, on=&#34;postcode&#34;)

    spharm = cudf.read_csv(scotland, usecols=[0, 6])
    spharm.rename(
        columns={&#34;﻿DispenserCode&#34;: &#34;pharmacy&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True
    )
    spharm[&#34;pharmacy&#34;] = spharm[&#34;pharmacy&#34;].astype(str)
    spharm[&#34;postcode&#34;] = fix_postcodes(spharm[&#34;postcode&#34;])
    spharm_pc = spharm.merge(postcodes, on=&#34;postcode&#34;)

    assert len(epharm) == len(epharm_pc), &#34;Missing UK pharm postcodes&#34;
    assert len(spharm) == len(spharm_pc), &#34;Missing Scotland pharm postcodes&#34;
    return epharm_pc.append(spharm_pc)


def clean_ae(
    eng_ae: Path, eng_hospitals: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    breakpoint()
    eae = cudf.read_csv(eng_ae)
    ehos = cudf.read_csv(eng_hospitals)
    ehos.columns
    eae.columns
    eae.columns
    eae.head()

    ehos = cudf.read_csv(eng_hospitals, usecols=[0, 9, 11], header=None)
    ehos.rename(columns={&#34;0&#34;: &#34;hospital&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;}, inplace=True)
    ehos = ehos[ehos[&#34;close&#34;].isna()].drop(&#34;close&#34;, axis=1)  # filter out closed
    ehos[&#34;postcode&#34;] = fix_postcodes(ehos[&#34;postcode&#34;])

    # remove isle of man, jersey, gurnsey, northern ireland
    ehos = ehos[
        ~ehos[&#34;postcode&#34;].str.startswith(&#34;IM&#34;)
        &amp; ~ehos[&#34;postcode&#34;].str.startswith(&#34;JE&#34;)
        &amp; ~ehos[&#34;postcode&#34;].str.startswith(&#34;GY&#34;)
        &amp; ~ehos[&#34;postcode&#34;].str.startswith(&#34;BT&#34;)
    ]
    ehos_pc = ehos.merge(postcodes, on=&#34;postcode&#34;)

    shos = cudf.read_csv(
        scotland,
        usecols=[&#34;Location&#34;, &#34;Postcode&#34;],
    )
    shos.rename(columns={&#34;Location&#34;: &#34;hospital&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True)
    shos[&#34;postcode&#34;] = fix_postcodes(shos[&#34;postcode&#34;])
    shos_pc = shos.merge(postcodes, on=&#34;postcode&#34;)

    assert len(ehos) == len(ehos_pc), &#34;Missing UK hospital postcodes&#34;
    assert len(shos) == len(shos_pc), &#34;Missing Scotland hospital postcodes&#34;
    return ehos_pc.append(shos_pc)


def clean_air(path: Path, col: &#34;str&#34;):
    air: pd.DataFrame = pd.read_csv(path, skiprows=5, header=0)
    air = air[air[col] != &#34;MISSING&#34;]
    air[col] = air[col].astype(float)
    return air


def clean_greenspace_access(path: Path) -&gt; cudf.DataFrame:
    greenspace = gpd.read_file(path)
    greenspace[&#34;easting&#34;], greenspace[&#34;northing&#34;] = (
        greenspace.geometry.x.astype(&#34;int&#34;),
        greenspace.geometry.y.astype(&#34;int&#34;),
    )
    return cudf.DataFrame(greenspace.drop(&#34;geometry&#34;, axis=1)).loc[
        :, [&#34;id&#34;, &#34;easting&#34;, &#34;northing&#34;]
    ]


def clean_bluespace(dir: Path) -&gt; cudf.DataFrame:
    bluespace = gpd.GeoDataFrame(
        pd.concat([gpd.read_file(shp) for shp in dir.glob(&#34;*.shp&#34;)], ignore_index=True)
    )

    def keep_tuples(row):
        try:
            row = row[:2]
        except TypeError:
            row = &#34;DROP&#34;
        return row

    bluespace = (
        bluespace.simplify(25)
        .apply(lambda x: list(itertools.chain.from_iterable(mapping(x)[&#34;coordinates&#34;])))
        .explode()
        .apply(keep_tuples)
    )
    bluespace = (
        pd.DataFrame(
            bluespace[bluespace != &#34;DROP&#34;].tolist(), columns=[&#34;easting&#34;, &#34;northing&#34;]
        )
        .astype(&#34;int&#34;)
        .drop_duplicates()
    )
    return cudf.from_pandas(bluespace)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ahah.utils.clean_ae"><code class="name flex">
<span>def <span class="ident">clean_ae</span></span>(<span>eng_ae: pathlib.Path, eng_hospitals: pathlib.Path, scotland: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_ae(
    eng_ae: Path, eng_hospitals: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    breakpoint()
    eae = cudf.read_csv(eng_ae)
    ehos = cudf.read_csv(eng_hospitals)
    ehos.columns
    eae.columns
    eae.columns
    eae.head()

    ehos = cudf.read_csv(eng_hospitals, usecols=[0, 9, 11], header=None)
    ehos.rename(columns={&#34;0&#34;: &#34;hospital&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;}, inplace=True)
    ehos = ehos[ehos[&#34;close&#34;].isna()].drop(&#34;close&#34;, axis=1)  # filter out closed
    ehos[&#34;postcode&#34;] = fix_postcodes(ehos[&#34;postcode&#34;])

    # remove isle of man, jersey, gurnsey, northern ireland
    ehos = ehos[
        ~ehos[&#34;postcode&#34;].str.startswith(&#34;IM&#34;)
        &amp; ~ehos[&#34;postcode&#34;].str.startswith(&#34;JE&#34;)
        &amp; ~ehos[&#34;postcode&#34;].str.startswith(&#34;GY&#34;)
        &amp; ~ehos[&#34;postcode&#34;].str.startswith(&#34;BT&#34;)
    ]
    ehos_pc = ehos.merge(postcodes, on=&#34;postcode&#34;)

    shos = cudf.read_csv(
        scotland,
        usecols=[&#34;Location&#34;, &#34;Postcode&#34;],
    )
    shos.rename(columns={&#34;Location&#34;: &#34;hospital&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True)
    shos[&#34;postcode&#34;] = fix_postcodes(shos[&#34;postcode&#34;])
    shos_pc = shos.merge(postcodes, on=&#34;postcode&#34;)

    assert len(ehos) == len(ehos_pc), &#34;Missing UK hospital postcodes&#34;
    assert len(shos) == len(shos_pc), &#34;Missing Scotland hospital postcodes&#34;
    return ehos_pc.append(shos_pc)</code></pre>
</details>
</dd>
<dt id="ahah.utils.clean_air"><code class="name flex">
<span>def <span class="ident">clean_air</span></span>(<span>path: pathlib.Path, col: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_air(path: Path, col: &#34;str&#34;):
    air: pd.DataFrame = pd.read_csv(path, skiprows=5, header=0)
    air = air[air[col] != &#34;MISSING&#34;]
    air[col] = air[col].astype(float)
    return air</code></pre>
</details>
</dd>
<dt id="ahah.utils.clean_bluespace"><code class="name flex">
<span>def <span class="ident">clean_bluespace</span></span>(<span>dir: pathlib.Path) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_bluespace(dir: Path) -&gt; cudf.DataFrame:
    bluespace = gpd.GeoDataFrame(
        pd.concat([gpd.read_file(shp) for shp in dir.glob(&#34;*.shp&#34;)], ignore_index=True)
    )

    def keep_tuples(row):
        try:
            row = row[:2]
        except TypeError:
            row = &#34;DROP&#34;
        return row

    bluespace = (
        bluespace.simplify(25)
        .apply(lambda x: list(itertools.chain.from_iterable(mapping(x)[&#34;coordinates&#34;])))
        .explode()
        .apply(keep_tuples)
    )
    bluespace = (
        pd.DataFrame(
            bluespace[bluespace != &#34;DROP&#34;].tolist(), columns=[&#34;easting&#34;, &#34;northing&#34;]
        )
        .astype(&#34;int&#34;)
        .drop_duplicates()
    )
    return cudf.from_pandas(bluespace)</code></pre>
</details>
</dd>
<dt id="ahah.utils.clean_dentists"><code class="name flex">
<span>def <span class="ident">clean_dentists</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_dentists(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    edent = cudf.read_csv(england, usecols=[0, 9], header=None)
    edent.rename(columns={&#34;0&#34;: &#34;dentist&#34;, &#34;9&#34;: &#34;postcode&#34;}, inplace=True)
    edent[&#34;postcode&#34;] = fix_postcodes(edent[&#34;postcode&#34;])
    # remove isle of man pc
    edent = edent[~edent[&#34;postcode&#34;].str.startswith(&#34;IM&#34;)]
    edent_pc = edent.merge(postcodes, on=&#34;postcode&#34;)

    sdent = cudf.read_csv(scotland, usecols=[&#34;DentalPracticeCode&#34;, &#34;Postcode&#34;])
    sdent.rename(
        columns={&#34;DentalPracticeCode&#34;: &#34;dentist&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True
    )
    sdent[&#34;dentist&#34;] = sdent[&#34;dentist&#34;].astype(str)
    sdent[&#34;postcode&#34;] = fix_postcodes(sdent[&#34;postcode&#34;])
    sdent_pc = sdent.merge(postcodes, on=&#34;postcode&#34;)
    sdent_pc = find_partial_pc(sdent, sdent_pc, postcodes)

    assert len(edent) == len(edent_pc), &#34;Missing UK dentist postcodes&#34;
    assert len(sdent) == len(sdent_pc), &#34;Missing Scotland dentist postcodes&#34;
    return edent_pc.append(sdent_pc)</code></pre>
</details>
</dd>
<dt id="ahah.utils.clean_gpp"><code class="name flex">
<span>def <span class="ident">clean_gpp</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_gpp(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    egpp = cudf.read_csv(england, usecols=[0, 9, 11], header=None)
    egpp.rename(columns={&#34;0&#34;: &#34;gpp&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;}, inplace=True)

    # remove alderney + gurnsey + jersey + isle of man + british forces + closed hospitals
    egpp = egpp[egpp[&#34;close&#34;].isnull()][[&#34;gpp&#34;, &#34;postcode&#34;]].drop_duplicates()
    egpp[&#34;postcode&#34;] = fix_postcodes(egpp[&#34;postcode&#34;])
    egpp = egpp[
        ~egpp[&#34;gpp&#34;].str.startswith(&#34;ALD&#34;)
        &amp; ~egpp[&#34;gpp&#34;].str.startswith(&#34;GUE&#34;)
        &amp; ~egpp[&#34;gpp&#34;].str.startswith(&#34;JER&#34;)
    ]
    egpp = egpp[
        ~egpp[&#34;postcode&#34;].str.startswith(&#34;IM&#34;) &amp; ~egpp[&#34;postcode&#34;].str.startswith(&#34;BF&#34;)
    ]

    egpp_pc = egpp.merge(postcodes, on=&#34;postcode&#34;)
    egpp_pc = find_partial_pc(egpp, egpp_pc, postcodes)
    # fix one mistyped welsh postcode
    egpp_pc = egpp_pc.append(postcodes[postcodes[&#34;postcode&#34;] == &#34;LL55 1HU&#34;])

    sgpp = cudf.read_csv(scotland, usecols=[&#34;PracticeCode&#34;, &#34;Postcode&#34;])
    sgpp.rename(columns={&#34;PracticeCode&#34;: &#34;gpp&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True)
    sgpp[&#34;gpp&#34;] = sgpp[&#34;gpp&#34;].astype(str)
    sgpp[&#34;postcode&#34;] = fix_postcodes(sgpp[&#34;postcode&#34;])
    sgpp_pc = sgpp.merge(postcodes, on=&#34;postcode&#34;)

    assert len(egpp) == len(egpp_pc), &#34;Missing UK gpp postcodes&#34;
    assert len(sgpp) == len(sgpp_pc), &#34;Missing Scotland gpp postcodes&#34;
    return egpp_pc.append(sgpp_pc)</code></pre>
</details>
</dd>
<dt id="ahah.utils.clean_greenspace_access"><code class="name flex">
<span>def <span class="ident">clean_greenspace_access</span></span>(<span>path: pathlib.Path) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_greenspace_access(path: Path) -&gt; cudf.DataFrame:
    greenspace = gpd.read_file(path)
    greenspace[&#34;easting&#34;], greenspace[&#34;northing&#34;] = (
        greenspace.geometry.x.astype(&#34;int&#34;),
        greenspace.geometry.y.astype(&#34;int&#34;),
    )
    return cudf.DataFrame(greenspace.drop(&#34;geometry&#34;, axis=1)).loc[
        :, [&#34;id&#34;, &#34;easting&#34;, &#34;northing&#34;]
    ]</code></pre>
</details>
</dd>
<dt id="ahah.utils.clean_pharmacies"><code class="name flex">
<span>def <span class="ident">clean_pharmacies</span></span>(<span>england: pathlib.Path, scotland: pathlib.Path, postcodes: cudf.core.dataframe.DataFrame) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_pharmacies(
    england: Path, scotland: Path, postcodes: cudf.DataFrame
) -&gt; cudf.DataFrame:
    epharm = cudf.read_csv(england, header=None, usecols=[0, 9, 11])
    epharm.rename(
        columns={&#34;0&#34;: &#34;pharmacy&#34;, &#34;9&#34;: &#34;postcode&#34;, &#34;11&#34;: &#34;close&#34;}, inplace=True
    )

    # remove closed + isle of man
    epharm = epharm[epharm[&#34;close&#34;].isnull()][
        [&#34;pharmacy&#34;, &#34;postcode&#34;]
    ].drop_duplicates()
    epharm[&#34;postcode&#34;] = fix_postcodes(epharm[&#34;postcode&#34;])
    epharm = epharm[~epharm[&#34;postcode&#34;].str.startswith(&#34;IM&#34;)]
    epharm_pc = epharm.merge(postcodes, on=&#34;postcode&#34;)

    spharm = cudf.read_csv(scotland, usecols=[0, 6])
    spharm.rename(
        columns={&#34;﻿DispenserCode&#34;: &#34;pharmacy&#34;, &#34;Postcode&#34;: &#34;postcode&#34;}, inplace=True
    )
    spharm[&#34;pharmacy&#34;] = spharm[&#34;pharmacy&#34;].astype(str)
    spharm[&#34;postcode&#34;] = fix_postcodes(spharm[&#34;postcode&#34;])
    spharm_pc = spharm.merge(postcodes, on=&#34;postcode&#34;)

    assert len(epharm) == len(epharm_pc), &#34;Missing UK pharm postcodes&#34;
    assert len(spharm) == len(spharm_pc), &#34;Missing Scotland pharm postcodes&#34;
    return epharm_pc.append(spharm_pc)</code></pre>
</details>
</dd>
<dt id="ahah.utils.clean_postcodes"><code class="name flex">
<span>def <span class="ident">clean_postcodes</span></span>(<span>path: pathlib.Path, current: bool, scotland=True, wales=True) ‑> cudf.core.dataframe.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_postcodes(
    path: Path, current: bool, scotland=True, wales=True
) -&gt; cudf.DataFrame:
    postcodes = cudf.read_csv(
        path,
        usecols=[&#34;pcd&#34;, &#34;oseast1m&#34;, &#34;osnrth1m&#34;, &#34;doterm&#34;, &#34;ctry&#34;],
        dtype={
            &#34;pcd&#34;: &#34;str&#34;,
            &#34;oseast1m&#34;: &#34;int&#34;,
            &#34;osnrth1m&#34;: &#34;int&#34;,
            &#34;doterm&#34;: &#34;str&#34;,
            &#34;ctry&#34;: &#34;str&#34;,
        },
    )
    countries = [&#34;E92000001&#34;]
    if scotland:
        countries.append(&#34;S92000003&#34;)
    if wales:
        countries.append(&#34;W92000004&#34;)

    postcodes = postcodes[postcodes[&#34;ctry&#34;].isin(countries)].drop(&#34;ctry&#34;, axis=1)

    postcodes = postcodes.rename(
        columns={&#34;pcd&#34;: &#34;postcode&#34;, &#34;oseast1m&#34;: &#34;easting&#34;, &#34;osnrth1m&#34;: &#34;northing&#34;}
    )
    postcodes[&#34;postcode&#34;] = fix_postcodes(postcodes[&#34;postcode&#34;])
    postcodes = postcodes.dropna(subset=[&#34;easting&#34;, &#34;northing&#34;])

    if current:
        return postcodes[postcodes[&#34;doterm&#34;].isnull()].drop(&#34;doterm&#34;, axis=1)
    return postcodes.drop(&#34;doterm&#34;, axis=1)</code></pre>
</details>
</dd>
<dt id="ahah.utils.find_partial_pc"><code class="name flex">
<span>def <span class="ident">find_partial_pc</span></span>(<span>poi: Union[pandas.core.frame.DataFrame, cudf.core.dataframe.DataFrame], poi_pc: Union[pandas.core.frame.DataFrame, cudf.core.dataframe.DataFrame], postcodes: Union[pandas.core.frame.DataFrame, cudf.core.dataframe.DataFrame]) ‑> Union[pandas.core.frame.DataFrame, cudf.core.dataframe.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Find postcodes that have partially correct first characters</p>
<p>Splits postcodes into two and uses first half to match to likely nearest
correct postcode location if the postcode cannot be found in whole postcode
dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>poi</code></strong> :&ensp;<code>Union[pd.DataFrame, cudf.DataFrame]</code></dt>
<dd>POI dataframe containing series of postcodes</dd>
<dt><strong><code>poi_pc</code></strong> :&ensp;<code>Union[pd.DataFrame, cudf.DataFrame]</code></dt>
<dd>POI dataframe with missing postcodes</dd>
<dt><strong><code>postcodes</code></strong> :&ensp;<code>Union[pd.DataFrame, cudf.DataFrame]</code></dt>
<dd>Dataframe of all postcodes</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[pd.DataFrame, cudf.DataFrame]:</code></dt>
<dd>POI dataframe with inferred postcodes</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_partial_pc(
    poi: Union[pd.DataFrame, cudf.DataFrame],
    poi_pc: Union[pd.DataFrame, cudf.DataFrame],
    postcodes: Union[pd.DataFrame, cudf.DataFrame],
) -&gt; Union[pd.DataFrame, cudf.DataFrame]:
    &#34;&#34;&#34;
    Find postcodes that have partially correct first characters

    Splits postcodes into two and uses first half to match to likely nearest
    correct postcode location if the postcode cannot be found in whole postcode
    dataset.

    Parameters
    ----------
    poi : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe containing series of postcodes
    poi_pc : Union[pd.DataFrame, cudf.DataFrame]
        POI dataframe with missing postcodes
    postcodes : Union[pd.DataFrame, cudf.DataFrame]
        Dataframe of all postcodes

    Returns
    -------
    Union[pd.DataFrame, cudf.DataFrame]:
        POI dataframe with inferred postcodes
    &#34;&#34;&#34;
    # find approximate location of incorrect postcodes
    missing = poi[~poi[&#34;postcode&#34;].isin(poi_pc[&#34;postcode&#34;])]
    missing[&#34;partial&#34;] = missing[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]
    postcodes[&#34;partial&#34;] = postcodes[&#34;postcode&#34;].str.split(&#34; &#34;, expand=True)[0]
    poi_pc = poi_pc.append(
        missing.merge(
            postcodes[[&#34;partial&#34;, &#34;easting&#34;, &#34;northing&#34;]], on=&#34;partial&#34;
        ).drop_duplicates(&#34;partial&#34;)
    ).drop(&#34;partial&#34;, axis=1)
    postcodes.drop(&#34;partial&#34;, axis=1, inplace=True)
    return poi_pc</code></pre>
</details>
</dd>
<dt id="ahah.utils.fix_postcodes"><code class="name flex">
<span>def <span class="ident">fix_postcodes</span></span>(<span>series: Union[pandas.core.series.Series, cudf.core.series.Series]) ‑> Union[pandas.core.series.Series, cudf.core.series.Series]</span>
</code></dt>
<dd>
<div class="desc"><p>Ensure all postcodes follow correct spacing format</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>series</code></strong> :&ensp;<code>Union[pd.Series, cudf.Series]</code></dt>
<dd>Series of postcodes as strings</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[pd.Series, cudf.Series]:</code></dt>
<dd>Correctly formatted series of postcodes</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fix_postcodes(
    series: Union[pd.Series, cudf.Series]
) -&gt; Union[pd.Series, cudf.Series]:
    &#34;&#34;&#34;
    Ensure all postcodes follow correct spacing format

    Parameters
    ----------
    series : Union[pd.Series, cudf.Series]
        Series of postcodes as strings

    Returns
    -------
    Union[pd.Series, cudf.Series]:
        Correctly formatted series of postcodes
    &#34;&#34;&#34;
    series = series.str.replace(&#34; &#34;, &#34;&#34;)
    series = series.str[:-3] + &#34; &#34; + series.str[-3:]
    return series</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ahah.utils.Config"><code class="flex name class">
<span>class <span class="ident">Config</span></span>
</code></dt>
<dd>
<div class="desc"><p>Misc constants required throughout</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Config:
    &#34;&#34;&#34;Misc constants required throughout&#34;&#34;&#34;

    DATA_PATH = Path(&#34;data/&#34;)
    RAW_DATA = DATA_PATH / &#34;raw&#34;
    PROCESSED_DATA = DATA_PATH / &#34;processed&#34;
    OUT_DATA = DATA_PATH / &#34;out&#34;
    OSM_GRAPH = PROCESSED_DATA / &#34;osm&#34;

    POI_LIST = [
        &#34;gpp&#34;,
        &#34;dentists&#34;,
        &#34;pharmacies&#34;,
        &#34;hospitals&#34;,
        &#34;greenspace&#34;,
        &#34;bluespace&#34;,
    ]

    NODE_COLS = [&#34;node_id&#34;, &#34;easting&#34;, &#34;northing&#34;]
    EDGE_COLS = [&#34;source&#34;, &#34;target&#34;, &#34;time_weighted&#34;, &#34;length&#34;]

    # https://digital.nhs.uk/services/organisation-data-service/data-downloads
    # A&amp;E from https://www.england.nhs.uk/statistics/statistical-work-areas/ae-waiting-times-and-activity/ae-attendances-and-emergency-admissions-2020-21/
    NHS_URL = &#34;https://files.digital.nhs.uk/assets/ods/current/&#34;
    NHS_FILES = {
        # 26 February 2021
        &#34;gpp&#34;: &#34;epraccur.zip&#34;,
        # 26 February 2021
        &#34;dentists&#34;: &#34;egdpprac.zip&#34;,
        # 26 February 2021
        &#34;pharmacies&#34;: &#34;epharmacyhq.zip&#34;,
        # 25 February 2021
        &#34;hospitals&#34;: &#34;ets.zip&#34;,
    }
    NHS_SCOT_URL = &#34;https://www.opendata.nhs.scot/dataset/&#34;
    NHS_SCOT = {
        # GP Practices and List sizes April 2021
        &#34;gpp&#34;: &#34;f23655c3-6e23-4103-a511-a80d998adb90/resource&#34;
        &#34;/a794d603-95ab-4309-8c92-b48970478c14/download&#34;
        &#34;/practice_contactdetails_apr2021-open-data.csv&#34;,
        # Dental Practices December 2020
        &#34;dentists&#34;: &#34;2f218ba7-6695-4b22-867d-41383ae36de7/resource&#34;
        &#34;/20040f9f-e598-4237-8a12-8bc35c0b2959/download&#34;
        &#34;/nhs-dental-practices-and-nhs-dental-registrations-as-at-31st-december-2020.csv&#34;,
        # Current NHS Hospitals in Scotland 6th May, 2021
        &#34;hospitals&#34;: &#34;cbd1802e-0e04-4282-88eb-d7bdcfb120f0/resource&#34;
        &#34;/c698f450-eeed-41a0-88f7-c1e40a568acc/download&#34;
        &#34;/current-hospital_flagged20210506.csv&#34;,
        # Accident &amp; Emergency Sites 9th April, 2020
        &#34;ae&#34;: &#34;a877470a-06a9-492f-b9e8-992f758894d0/resource&#34;
        &#34;/1a4e3f48-3d9b-4769-80e9-3ef6d27852fe/download&#34;
        &#34;/hospital_site_list.csv&#34;,
        # Dispenser Details October 2020
        &#34;pharmacies&#34;: &#34;a30fde16-1226-49b3-b13d-eb90e39c2058/resource&#34;
        &#34;/d08bc753-c6dc-4dbd-8b37-ef439d3a7428/download&#34;
        &#34;/dispenser_contactdetails_oct2020_notabs.csv&#34;,
    }</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="ahah.utils.Config.DATA_PATH"><code class="name">var <span class="ident">DATA_PATH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.EDGE_COLS"><code class="name">var <span class="ident">EDGE_COLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.NHS_FILES"><code class="name">var <span class="ident">NHS_FILES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.NHS_SCOT"><code class="name">var <span class="ident">NHS_SCOT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.NHS_SCOT_URL"><code class="name">var <span class="ident">NHS_SCOT_URL</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.NHS_URL"><code class="name">var <span class="ident">NHS_URL</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.NODE_COLS"><code class="name">var <span class="ident">NODE_COLS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.OSM_GRAPH"><code class="name">var <span class="ident">OSM_GRAPH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.OUT_DATA"><code class="name">var <span class="ident">OUT_DATA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.POI_LIST"><code class="name">var <span class="ident">POI_LIST</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.PROCESSED_DATA"><code class="name">var <span class="ident">PROCESSED_DATA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="ahah.utils.Config.RAW_DATA"><code class="name">var <span class="ident">RAW_DATA</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ahah" href="index.html">ahah</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ahah.utils.clean_ae" href="#ahah.utils.clean_ae">clean_ae</a></code></li>
<li><code><a title="ahah.utils.clean_air" href="#ahah.utils.clean_air">clean_air</a></code></li>
<li><code><a title="ahah.utils.clean_bluespace" href="#ahah.utils.clean_bluespace">clean_bluespace</a></code></li>
<li><code><a title="ahah.utils.clean_dentists" href="#ahah.utils.clean_dentists">clean_dentists</a></code></li>
<li><code><a title="ahah.utils.clean_gpp" href="#ahah.utils.clean_gpp">clean_gpp</a></code></li>
<li><code><a title="ahah.utils.clean_greenspace_access" href="#ahah.utils.clean_greenspace_access">clean_greenspace_access</a></code></li>
<li><code><a title="ahah.utils.clean_pharmacies" href="#ahah.utils.clean_pharmacies">clean_pharmacies</a></code></li>
<li><code><a title="ahah.utils.clean_postcodes" href="#ahah.utils.clean_postcodes">clean_postcodes</a></code></li>
<li><code><a title="ahah.utils.find_partial_pc" href="#ahah.utils.find_partial_pc">find_partial_pc</a></code></li>
<li><code><a title="ahah.utils.fix_postcodes" href="#ahah.utils.fix_postcodes">fix_postcodes</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ahah.utils.Config" href="#ahah.utils.Config">Config</a></code></h4>
<ul class="two-column">
<li><code><a title="ahah.utils.Config.DATA_PATH" href="#ahah.utils.Config.DATA_PATH">DATA_PATH</a></code></li>
<li><code><a title="ahah.utils.Config.EDGE_COLS" href="#ahah.utils.Config.EDGE_COLS">EDGE_COLS</a></code></li>
<li><code><a title="ahah.utils.Config.NHS_FILES" href="#ahah.utils.Config.NHS_FILES">NHS_FILES</a></code></li>
<li><code><a title="ahah.utils.Config.NHS_SCOT" href="#ahah.utils.Config.NHS_SCOT">NHS_SCOT</a></code></li>
<li><code><a title="ahah.utils.Config.NHS_SCOT_URL" href="#ahah.utils.Config.NHS_SCOT_URL">NHS_SCOT_URL</a></code></li>
<li><code><a title="ahah.utils.Config.NHS_URL" href="#ahah.utils.Config.NHS_URL">NHS_URL</a></code></li>
<li><code><a title="ahah.utils.Config.NODE_COLS" href="#ahah.utils.Config.NODE_COLS">NODE_COLS</a></code></li>
<li><code><a title="ahah.utils.Config.OSM_GRAPH" href="#ahah.utils.Config.OSM_GRAPH">OSM_GRAPH</a></code></li>
<li><code><a title="ahah.utils.Config.OUT_DATA" href="#ahah.utils.Config.OUT_DATA">OUT_DATA</a></code></li>
<li><code><a title="ahah.utils.Config.POI_LIST" href="#ahah.utils.Config.POI_LIST">POI_LIST</a></code></li>
<li><code><a title="ahah.utils.Config.PROCESSED_DATA" href="#ahah.utils.Config.PROCESSED_DATA">PROCESSED_DATA</a></code></li>
<li><code><a title="ahah.utils.Config.RAW_DATA" href="#ahah.utils.Config.RAW_DATA">RAW_DATA</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>
